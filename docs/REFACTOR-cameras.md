### AI Agent Instructions

Your task is to refactor the Meraki MV camera integration to properly handle various camera models and their unique features. This requires a **granular, type-aware approach** that goes beyond basic video streams. The goal is to dynamically expose all supported sensors and controls for each specific camera model.

1.  **Refactor `MerakiRepository` for Camera-Specific Endpoints**: Identify and implement the necessary API endpoints to retrieve a camera's specific capabilities. This may include endpoints for `getDeviceCameraAnalyticsOverview`, `getDeviceCameraAnalyticsZones`, and `getDeviceCameraVideoLink`.
2.  **Modularize Camera-Specific Logic**: Create a new, dedicated `CameraService` to handle all camera-related functions. This service will use the repository to fetch data and expose methods that are agnostic of the camera model, while the underlying logic handles the model-specific differences.
3.  **Implement a Type-Aware `MVHandler`**: The `MVHandler` must be refactored to be model-aware. During discovery, it should query the device for its model type and then conditionally create entities based on that model's supported features.
4.  **Enforce Strict Code Separation**: As instructed previously, break down complex logic into small, single-purpose functions. No file should exceed 300 lines, and indentation should be limited to a maximum of three levels.

***

### Refactor Plan for Meraki MV Cameras

This plan builds on the existing architecture to implement a dynamic and feature-rich integration for Meraki MV cameras, properly handling the unique capabilities of each model.

#### Phase 1: API and Repository Updates

1.  **Enhance `MerakiApiClient`**:
    * Add new methods to retrieve **camera analytics data** (`get_device_camera_analytics`, `get_network_camera_analytics_history`). These endpoints allow access to rich data like object counts (people/vehicles) and motion history.
    * Add a method to get **live video stream URLs** (`get_device_camera_video_link`), which is the correct way to get the RTSP stream.

2.  **Add `CameraRepository` Methods**:
    * Create a new `CameraRepository` or expand the existing `MerakiRepository` to include camera-specific methods. This repository layer will abstract the different API calls based on a camera's model and capabilities.
    * Methods should include `get_camera_features(serial)` to retrieve a camera's model-specific capabilities, `get_analytics_data(serial)` to fetch object detection and motion data, and `get_video_url(serial)` for the stream.

#### Phase 2: Create a Dedicated Camera Service

1.  **Develop `CameraService` (`meraki_ha/services/camera_service.py`)**:
    * This new service will be injected with the `MerakiRepository`.
    * It will contain methods like `get_supported_analytics(serial)` that query the repository and return a list of features (e.g., `["person_detection", "vehicle_detection"]`).
    * Other methods will retrieve the actual analytics data and the video stream URL. The `CameraService`'s job is to shield the handlers from the complexities of the repository's API calls.

#### Phase 3: Dynamic Entity Creation with `MVHandler`

1.  **Refactor `MVHandler`**:
    * Update the `MVHandler` to be **type-aware**. When it's created, it should get the device's model and query the `CameraService` for supported features.
    * The handler will then **conditionally create** Home Assistant entities based on the returned feature list.
        * **Camera Entity**: Always create a base camera entity for the video stream. The stream URL will come from the `CameraService`.
        * **Sensor Entities**: If the `CameraService` reports "person_detection" is supported, create a `person_count` sensor. If it supports "vehicle_detection," create a `vehicle_count` sensor.
        * **Binary Sensor Entities**: Create motion detection binary sensors based on motion history data from the `CameraService`.
        * **Button Entities**: For models that support snapshots, create a "Take Snapshot" button that calls the snapshot API endpoint via the `CameraService`.

2.  **Update `config_flow`**:
    * Ensure the `CameraService` is instantiated and injected into the `MVHandler`.

#### Phase 4: Testing and Cleanup

1.  **Create Model-Specific Mock Data**: When testing, use mock API responses that represent different camera models (e.g., one mock for an MV12, another for an MV93 with 360Â° view and analytics). This will allow you to test that the `MVHandler` correctly creates the right entities for each model. 
2.  **Remove Legacy Code**: Delete any old code that handles MV cameras in a monolithic or non-modular way, ensuring all new logic is routed through the repository and the new `CameraService`.
